{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c96864be-e271-4063-84fd-5400c493e6a3",
   "metadata": {},
   "source": [
    "# Практическое занятие 4. Оценка качества поиска\n",
    "\n",
    "Давайте реализуем в коде несколько метрик, о которых говорилось на лекции: MAP, NDCG и pFound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388dd7a8-0158-48f4-abbb-c95264407179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc7012-1220-4ca8-82e2-1ca1a19e7873",
   "metadata": {},
   "source": [
    "Для расчёта каждой метрики напишем отдельную функцию. Все функции будут принимать список чисел &mdash; оценки релевантности документов в порядке выдачи &mdash; а также число $k$ &mdash; глубину выдачи, для которой будет рассчитываться метрика."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562cd7db-7df2-4cf3-beb1-f234fe37f18c",
   "metadata": {},
   "source": [
    "Напишем сначала вспомогательную функцию для проверки того, что переданные нам оценки находятся в диапазоне $[0, 1]$ и что размер выдачи не меньше $k$. Это пригодится нам в расчёте всех трёх метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb166e-07f1-4759-a353-61b147339313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_serp(serp: list[float], k: int):\n",
    "\tassert len(serp) >= k > 0\n",
    "\tassert all(0 <= rel <= 1 for rel in serp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ca219d3-7798-4d12-9f69-ca812f348353",
   "metadata": {},
   "source": [
    "## 1. Average precision\n",
    "\n",
    "Average precision рассчитывается для бинарных оценок релевантности, и это надо не забыть проверить. Формула для расчета: $AP@k = {1\\over k}\\sum\\limits_{i=1}^{k} P@i \\times Rel(D_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932cc3f-e69e-4204-a65d-7d2f9c55bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Дополните/измените код функции ниже, чтобы метрика рассчитывалась верно.\n",
    "\"\"\"\n",
    "def ap(serp: list[int], k: int) -> float:\n",
    "    validate_serp(serp, k)\n",
    "    assert all(rel in [0, 1] for rel in serp)\n",
    "    sum_ = 0\n",
    "    for i in range(k):\n",
    "        if serp[i] == 1:\n",
    "            sum_ += 1\n",
    "    return sum_ / k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a11261b-011b-46c6-8e7c-dadf0cdde3ea",
   "metadata": {},
   "source": [
    "## 2. DCG\n",
    "\n",
    "Формула для DCG: $DCG_k = \\sum\\limits_{i=1}^{k} {{rel_i}\\over{\\log_2(i+1)}}$. Здесь оценки релевантности уже могут быть любыми (в диапазоне $[0, 1]$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831e9a8-24ac-488e-97f7-dc68b43bf9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCG(serp: list[float], k: int) -> float:\n",
    "    validate_serp(serp, k)\n",
    "    sum_ = 0\n",
    "    for i in range(k):\n",
    "        pass  # ваш код\n",
    "    return sum_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb12927c-eb45-497b-a839-d9e75547ec20",
   "metadata": {},
   "source": [
    "### NDCG\n",
    "\n",
    "Вспомним, что NDCG &mdash; это DCG, нормализованный на идеальный DCG для данной коллекции (IDCG). Таким образом, раз считать просто DCG мы уже умеем, то надо научиться считать сначала IDCG, а уже из него рассчитывать NDCG. Формула такова: $IDCG_k = \\sum\\limits_{i=1}^{|REL_k|}{2^{rel_i} - 1\\over{\\log_2(i+1)}}$, где $REL_k$ — все релевантные документы, отсортированные по убыванию релевантности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4e0f1-ddf0-48ef-b93d-acd633c66ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG(serp: list[float], k: int) -> float:\n",
    "    def IDCG(serp: list[float], k: int) -> float:\n",
    "        return 0  # ваш код вместо 0\n",
    "\n",
    "    return DCG(serp, k) / IDCG(serp, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540ca5c-ac4c-4fd3-b4ad-9c587300d641",
   "metadata": {},
   "source": [
    "## 3. pFound\n",
    "\n",
    "Идея этой метрики, как и предыдущих, в том, что пользователь просматривает выдачу сверху вниз, но:\n",
    "- прекращает просмотр с вероятностью, равной релевантности очередного документа,\n",
    "- либо может прекратить просмотр просто так с вероятностью $pBreak$.\n",
    "\n",
    "Формулы:\n",
    "\n",
    "$pFound_k = \\sum\\limits_{i=1}^{k} pLook_i \\times pRel_i$\n",
    "\n",
    "$pLook_i = pLook_{i-1} \\times (1 - pRel_{i-1}) \\times (1 - pBreak)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ed207-e6db-4fcf-a1bc-a11f27737627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pFound(serp: list[float], k: int, pBreak: float = 0.15) -> float:\n",
    "    validate_serp(serp, k)\n",
    "    sum_ = 0\n",
    "    pLook = [None] * k\n",
    "    pLook[0] = 1.0  # верхний документ точно будет просмотрен\n",
    "\n",
    "    for i in range(k):\n",
    "        # ваш код здесь\n",
    "        sum_ += pLook[i] * serp[i]\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37418c07-b848-4d95-891c-9695d55918da",
   "metadata": {},
   "source": [
    "## Тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fee801-0d97-402c-b380-d89deaf0a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(actual: float, expected: float):\n",
    "    assert round(actual, 3) == expected, f\"Expected value: {expected:.3f}, actual value: {actual:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31b13a-e5be-4d08-b0b1-4fe68cb8cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check(ap([1, 0, 0, 1], 4), 0.375)\n",
    "check(ap([1, 1, 0, 0], 4), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4b0a3-406c-47a5-9e58-4857f52f7fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check(DCG([0.4, 0, 0.2, 0.2, 0], 5), 0.586)\n",
    "check(NDCG([0.4, 0, 0.2, 0.2, 0], 5), 0.936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf7d09-5fb7-4c6e-8f83-645e69b19981",
   "metadata": {},
   "outputs": [],
   "source": [
    "check(pFound([0.4, 0.1, 0, 0, 0.1], 3), 0.451)\n",
    "check(pFound([0.4, 0.1, 0.1, 0, 0], 5), 0.49)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
